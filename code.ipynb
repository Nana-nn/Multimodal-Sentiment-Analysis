{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18475,"status":"ok","timestamp":1657350413385,"user":{"displayName":"y fengyu","userId":"14118958655840234398"},"user_tz":-480},"id":"s_ztoXHwek8T","outputId":"431720d6-e0f0-48ea-fded-09a7b7519e5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657350413386,"user":{"displayName":"y fengyu","userId":"14118958655840234398"},"user_tz":-480},"id":"JMJfdB__fDwM","outputId":"2fe2f3c4-c340-4853-8272-656955e9dab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Multimodal-Sentiment-Analysis/code\n"]}],"source":["cd /content/drive/MyDrive/Multimodal-Sentiment-Analysis/code"]},{"cell_type":"code","source":["# !python get_data.py"],"metadata":{"id":"58Sx5HeNaauH","executionInfo":{"status":"ok","timestamp":1657350413386,"user_tz":-480,"elapsed":7,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dm0NkJzUrXOp","executionInfo":{"status":"ok","timestamp":1657350422539,"user_tz":-480,"elapsed":9159,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}},"outputId":"018606d2-b1a7-4685-9281-78a58ccf9f0c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 8.5 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 44.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.1 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 70.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9840,"status":"ok","timestamp":1657350432373,"user":{"displayName":"y fengyu","userId":"14118958655840234398"},"user_tz":-480},"id":"xkg7SWb6nnyg","outputId":"83fa65c6-4c0f-4680-ae18-3bb86bba0de3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting boto3\n","  Downloading boto3-1.24.26-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 8.2 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.9 MB/s \n","\u001b[?25hCollecting botocore<1.28.0,>=1.27.26\n","  Downloading botocore-1.27.26-py3-none-any.whl (9.0 MB)\n","\u001b[K     |████████████████████████████████| 9.0 MB 62.1 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 70.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.26->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.26->boto3) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.10 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.24.26 botocore-1.27.26 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.10\n"]}],"source":["pip install boto3"]},{"cell_type":"markdown","source":["只输入图片"],"metadata":{"id":"7ao1BJpwQfyE"}},{"cell_type":"code","source":["!sh run_only_image.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5PYck9yrZo1","executionInfo":{"status":"ok","timestamp":1657358905679,"user_tz":-480,"elapsed":153001,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}},"outputId":"1e71826a-10a2-46a3-f09e-452a723574aa"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["run_only_image.sh: 2: run_only_image.sh: \r: not found\n","/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing mymodel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing mymodel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing mymodel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of mymodel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['BertEncoder.layer.9.attention.self.query.bias', 'BertEncoder.layer.8.attention.self.query.bias', 'BertEncoder.layer.3.attention.self.query.weight', 'img_pooler.dense.weight', 'BertEncoder.layer.5.attention.self.query.bias', 'BertEncoder.layer.4.attention.self.query.weight', 'BertEncoder.layer.9.output.LayerNorm.bias', 'BertEncoder.layer.8.intermediate.dense.weight', 'BertEncoder.layer.2.attention.output.dense.bias', 'BertEncoder.layer.9.attention.self.value.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.weight', 'BertEncoder.layer.4.attention.output.dense.weight', 'BertEncoder.layer.7.attention.self.value.weight', 'BertEncoder.layer.3.attention.self.value.bias', 'BertEncoder.layer.11.attention.self.query.weight', 'BertEncoder.layer.3.output.dense.weight', 'BertEncoder.layer.0.attention.self.query.bias', 'BertEncoder.layer.0.attention.self.key.bias', 'BertEncoder.layer.9.attention.self.key.bias', 'BertEncoder.layer.4.output.dense.bias', 'cross_attention.layer.0.intermediate.dense.bias', 'BertEncoder.layer.10.attention.self.key.bias', 'BertEncoder.layer.7.attention.output.dense.weight', 'BertEncoder.layer.6.attention.self.query.bias', 'BertEncoder.layer.6.intermediate.dense.bias', 'BertEncoder.layer.9.attention.self.value.weight', 'BertEncoder.layer.3.attention.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.self.query.weight', 'BertEncoder.layer.8.attention.output.dense.bias', 'BertEncoder.layer.4.attention.output.LayerNorm.bias', 'cross_attention.layer.0.attention.output.dense.bias', 'BertEncoder.layer.10.attention.output.dense.bias', 'BertEncoder.layer.0.intermediate.dense.weight', 'cross_attention.layer.0.attention.self.value.bias', 'BertEncoder.layer.10.attention.self.query.bias', 'BertEncoder.layer.9.intermediate.dense.bias', 'BertEncoder.layer.7.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.self.key.weight', 'BertEncoder.layer.7.attention.output.dense.bias', 'BertEncoder.layer.0.intermediate.dense.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.self.query.weight', 'BertEncoder.layer.3.attention.output.dense.bias', 'BertEncoder.layer.8.output.LayerNorm.weight', 'linear.weight', 'BertEncoder.layer.1.output.dense.bias', 'BertEncoder.layer.4.intermediate.dense.weight', 'BertEncoder.layer.9.attention.output.LayerNorm.bias', 'cross_attention.layer.0.attention.self.query.weight', 'BertEncoder.layer.9.output.dense.weight', 'BertEncoder.layer.10.output.LayerNorm.weight', 'BertEncoder.layer.2.intermediate.dense.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.self.key.bias', 'BertEncoder.layer.9.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.self.query.bias', 'BertEncoder.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.3.intermediate.dense.weight', 'BertEncoder.layer.2.attention.output.LayerNorm.bias', 'cross_attention.layer.0.attention.self.query.bias', 'BertEncoder.layer.7.attention.self.query.bias', 'BertEncoder.layer.5.output.LayerNorm.bias', 'BertEncoder.layer.10.output.dense.bias', 'BertEncoder.layer.6.output.LayerNorm.weight', 'BertEncoder.layer.10.intermediate.dense.weight', 'BertEncoder.layer.3.attention.self.value.weight', 'BertEncoder.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.self.query.bias', 'BertEncoder.layer.7.attention.self.key.bias', 'BertEncoder.layer.10.attention.self.key.weight', 'BertEncoder.layer.8.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.output.dense.weight', 'BertEncoder.layer.7.intermediate.dense.weight', 'BertEncoder.layer.5.attention.self.key.bias', 'BertEncoder.layer.0.output.dense.weight', 'BertEncoder.layer.1.attention.self.key.weight', 'BertEncoder.layer.5.output.LayerNorm.weight', 'BertEncoder.layer.6.output.dense.weight', 'BertEncoder.layer.4.attention.output.LayerNorm.weight', 'BertEncoder.layer.11.attention.self.key.weight', 'BertEncoder.layer.10.attention.self.value.bias', 'BertEncoder.layer.8.attention.self.value.bias', 'BertEncoder.layer.5.attention.self.query.weight', 'BertEncoder.layer.5.output.dense.bias', 'BertEncoder.layer.5.attention.self.value.bias', 'BertEncoder.layer.1.attention.self.query.bias', 'cross_attention.layer.0.output.dense.bias', 'BertEncoder.layer.2.attention.output.LayerNorm.weight', 'BertEncoder.layer.9.intermediate.dense.weight', 'cross_attention.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.8.output.dense.weight', 'classifier.weight', 'BertEncoder.layer.3.attention.self.key.bias', 'BertEncoder.layer.7.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.attention.self.key.weight', 'BertEncoder.layer.1.intermediate.dense.weight', 'BertEncoder.layer.6.attention.self.key.bias', 'BertEncoder.layer.0.attention.self.value.weight', 'BertEncoder.layer.1.intermediate.dense.bias', 'BertEncoder.layer.8.attention.self.query.weight', 'BertEncoder.layer.1.attention.output.LayerNorm.bias', 'BertEncoder.layer.10.output.LayerNorm.bias', 'BertEncoder.layer.2.output.dense.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.weight', 'BertEncoder.layer.1.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.self.value.weight', 'cross_attention.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.bias', 'text_pooler.dense.bias', 'BertEncoder.layer.0.attention.self.query.weight', 'BertEncoder.layer.7.attention.output.LayerNorm.weight', 'BertEncoder.layer.7.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.query.weight', 'BertEncoder.layer.6.attention.self.query.weight', 'BertEncoder.layer.8.attention.self.key.bias', 'BertEncoder.layer.0.output.dense.bias', 'BertEncoder.layer.0.attention.output.dense.weight', 'BertEncoder.layer.7.output.dense.bias', 'BertEncoder.layer.11.intermediate.dense.bias', 'BertEncoder.layer.3.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.self.value.bias', 'BertEncoder.layer.2.intermediate.dense.weight', 'linear.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.self.key.bias', 'text_pooler.dense.weight', 'BertEncoder.layer.5.intermediate.dense.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.bias', 'BertEncoder.layer.3.attention.output.LayerNorm.bias', 'BertEncoder.layer.2.output.LayerNorm.weight', 'cross_attention.layer.0.attention.self.key.bias', 'BertEncoder.layer.3.output.dense.bias', 'BertEncoder.layer.11.attention.output.dense.weight', 'BertEncoder.layer.2.attention.output.dense.weight', 'BertEncoder.layer.9.attention.output.dense.bias', 'text_pooler1.dense.bias', 'BertEncoder.layer.0.attention.output.dense.bias', 'BertEncoder.layer.4.output.dense.weight', 'BertEncoder.layer.11.attention.self.key.bias', 'cross_attention.layer.0.attention.self.key.weight', 'BertEncoder.layer.11.output.dense.weight', 'BertEncoder.layer.9.attention.output.dense.weight', 'BertEncoder.layer.6.attention.self.key.weight', 'text_pooler1.dense.weight', 'BertEncoder.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.output.dense.weight', 'BertEncoder.layer.1.attention.self.value.weight', 'classifier.bias', 'BertEncoder.layer.8.intermediate.dense.bias', 'BertEncoder.layer.4.output.LayerNorm.bias', 'BertEncoder.layer.7.intermediate.dense.bias', 'BertEncoder.layer.4.attention.self.key.weight', 'BertEncoder.layer.9.output.dense.bias', 'BertEncoder.layer.6.output.LayerNorm.bias', 'BertEncoder.layer.6.attention.output.dense.bias', 'BertEncoder.layer.11.attention.self.value.weight', 'BertEncoder.layer.10.intermediate.dense.bias', 'BertEncoder.layer.9.attention.self.key.weight', 'BertEncoder.layer.9.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.self.value.weight', 'BertEncoder.layer.4.attention.self.value.bias', 'BertEncoder.layer.3.intermediate.dense.bias', 'BertEncoder.layer.8.attention.self.value.weight', 'BertEncoder.layer.5.attention.output.dense.bias', 'BertEncoder.layer.1.attention.output.dense.weight', 'img_pooler.dense.bias', 'BertEncoder.layer.4.attention.self.value.weight', 'BertEncoder.layer.6.attention.output.LayerNorm.weight', 'cross_attention.layer.0.output.dense.weight', 'BertEncoder.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.output.dense.bias', 'cross_attention.layer.0.attention.self.value.weight', 'BertEncoder.layer.3.attention.self.query.bias', 'BertEncoder.layer.11.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.output.dense.weight', 'BertEncoder.layer.5.attention.self.key.weight', 'BertEncoder.layer.9.attention.self.query.weight', 'BertEncoder.layer.2.output.dense.weight', 'BertEncoder.layer.10.attention.output.dense.weight', 'BertEncoder.layer.11.intermediate.dense.weight', 'BertEncoder.layer.1.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.output.dense.bias', 'BertEncoder.layer.11.attention.self.value.bias', 'cross_attention.layer.0.output.LayerNorm.weight', 'cross_attention.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.output.LayerNorm.weight', 'BertEncoder.layer.5.output.dense.weight', 'cross_attention.layer.0.intermediate.dense.weight', 'BertEncoder.layer.0.attention.self.key.weight', 'BertEncoder.layer.2.attention.self.query.weight', 'BertEncoder.layer.5.attention.self.value.weight', 'BertEncoder.layer.11.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.output.dense.weight', 'BertEncoder.layer.1.attention.output.dense.bias', 'BertEncoder.layer.1.attention.self.value.bias', 'BertEncoder.layer.2.attention.self.query.bias', 'BertEncoder.layer.3.attention.output.dense.weight', 'BertEncoder.layer.4.intermediate.dense.bias', 'BertEncoder.layer.7.attention.self.value.bias', 'BertEncoder.layer.5.attention.output.dense.weight', 'cross_attention.layer.0.attention.output.dense.weight', 'BertEncoder.layer.3.output.LayerNorm.bias', 'BertEncoder.layer.6.intermediate.dense.weight', 'BertEncoder.layer.0.attention.self.value.bias', 'BertEncoder.layer.4.attention.output.dense.bias', 'BertEncoder.layer.5.intermediate.dense.weight', 'BertEncoder.layer.8.attention.self.key.weight', 'BertEncoder.layer.11.output.dense.bias', 'BertEncoder.layer.6.attention.self.value.bias', 'BertEncoder.layer.3.attention.self.key.weight', 'BertEncoder.layer.1.output.dense.weight', 'BertEncoder.layer.8.output.dense.bias', 'BertEncoder.layer.10.attention.self.value.weight', 'BertEncoder.layer.2.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.key.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","3699\n","07/09/2022 09:26:34 - INFO - processors.util -   Start Training\n","epoch 0 traning loss 0.9393586478172204: 100% 78/78 [00:07<00:00,  9.89it/s]\n","07/09/2022 09:26:41 - INFO - processors.util -   Start Evaluation\n","epoch 0 dev loss 0.8916455224940651: 100% 19/19 [00:01<00:00, 16.99it/s]\n","eval_accuracy: 0.6079734219269103 f_score: 0.5279819062528098\n","epoch 1 traning loss 0.8627064957832679: 100% 78/78 [00:08<00:00,  9.05it/s]\n","07/09/2022 09:26:56 - INFO - processors.util -   Start Evaluation\n","epoch 1 dev loss 0.8741603838770013: 100% 19/19 [00:01<00:00, 12.56it/s]\n","eval_accuracy: 0.6013289036544851 f_score: 0.5050397418803545\n","epoch 2 traning loss 0.8478617752209688: 100% 78/78 [00:08<00:00,  8.96it/s]\n","07/09/2022 09:27:06 - INFO - processors.util -   Start Evaluation\n","epoch 2 dev loss 0.8862399866706446: 100% 19/19 [00:01<00:00, 17.10it/s]\n","eval_accuracy: 0.5980066445182725 f_score: 0.49125537497630517\n","epoch 3 traning loss 0.8384962112475665: 100% 78/78 [00:07<00:00,  9.91it/s]\n","07/09/2022 09:27:15 - INFO - processors.util -   Start Evaluation\n","epoch 3 dev loss 0.8763960348932367: 100% 19/19 [00:01<00:00, 16.33it/s]\n","eval_accuracy: 0.6046511627906976 f_score: 0.5447047478900229\n","epoch 4 traning loss 0.8327706310993586: 100% 78/78 [00:07<00:00,  9.94it/s]\n","07/09/2022 09:27:24 - INFO - processors.util -   Start Evaluation\n","epoch 4 dev loss 0.8742401599884033: 100% 19/19 [00:01<00:00, 17.04it/s]\n","eval_accuracy: 0.6212624584717608 f_score: 0.573100659225595\n","epoch 5 traning loss 0.8143140352689303: 100% 78/78 [00:08<00:00,  9.13it/s]\n","07/09/2022 09:27:38 - INFO - processors.util -   Start Evaluation\n","epoch 5 dev loss 0.8729246792040373: 100% 19/19 [00:01<00:00, 11.89it/s]\n","eval_accuracy: 0.6212624584717608 f_score: 0.5722505056494651\n","epoch 6 traning loss 0.7994812673483139: 100% 78/78 [00:08<00:00,  8.94it/s]\n","07/09/2022 09:27:53 - INFO - processors.util -   Start Evaluation\n","epoch 6 dev loss 0.876030212954471: 100% 19/19 [00:01<00:00, 12.04it/s]\n","eval_accuracy: 0.6179401993355482 f_score: 0.5660316500107415\n","epoch 7 traning loss 0.7969140723729745: 100% 78/78 [00:08<00:00,  8.70it/s]\n","07/09/2022 09:28:04 - INFO - processors.util -   Start Evaluation\n","epoch 7 dev loss 0.8801143545853464: 100% 19/19 [00:01<00:00, 16.95it/s]\n","eval_accuracy: 0.6013289036544851 f_score: 0.522636089279086\n","epoch 8 traning loss 0.7882052919803522: 100% 78/78 [00:07<00:00, 10.01it/s]\n","07/09/2022 09:28:13 - INFO - processors.util -   Start Evaluation\n","epoch 8 dev loss 0.8771402929958544: 100% 19/19 [00:01<00:00, 17.05it/s]\n","eval_accuracy: 0.6079734219269103 f_score: 0.5338251289803535\n","epoch 9 traning loss 0.7902789933559222: 100% 78/78 [00:07<00:00,  9.96it/s]\n","07/09/2022 09:28:22 - INFO - processors.util -   Start Evaluation\n","epoch 9 dev loss 0.8763404708159598: 100% 19/19 [00:01<00:00, 16.93it/s]\n","eval_accuracy: 0.6146179401993356 f_score: 0.5427392897680698\n"]}]},{"cell_type":"markdown","source":["只输入文字"],"metadata":{"id":"_YQngkRoQmUs"}},{"cell_type":"code","source":["!sh run_only_text.sh "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwa81wl7Xem2","executionInfo":{"status":"ok","timestamp":1657360505360,"user_tz":-480,"elapsed":287553,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}},"outputId":"10a3d1a6-1efe-494e-a161-c291e02d1404"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing mymodel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing mymodel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing mymodel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of mymodel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cross_attention.layer.0.output.dense.bias', 'BertEncoder.layer.5.output.dense.weight', 'BertEncoder.layer.5.output.LayerNorm.bias', 'cross_attention.layer.0.attention.self.value.bias', 'BertEncoder.layer.7.attention.output.LayerNorm.weight', 'BertEncoder.layer.5.attention.self.query.bias', 'BertEncoder.layer.4.attention.self.key.weight', 'BertEncoder.layer.2.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.output.dense.weight', 'BertEncoder.layer.8.output.LayerNorm.weight', 'BertEncoder.layer.10.output.dense.bias', 'BertEncoder.layer.10.output.LayerNorm.weight', 'BertEncoder.layer.11.intermediate.dense.weight', 'BertEncoder.layer.11.intermediate.dense.bias', 'BertEncoder.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.output.dense.weight', 'BertEncoder.layer.7.attention.self.key.weight', 'BertEncoder.layer.7.attention.self.value.weight', 'BertEncoder.layer.6.attention.output.dense.weight', 'BertEncoder.layer.2.attention.output.LayerNorm.bias', 'BertEncoder.layer.0.output.dense.weight', 'BertEncoder.layer.6.attention.self.key.weight', 'BertEncoder.layer.2.intermediate.dense.bias', 'BertEncoder.layer.3.output.dense.weight', 'BertEncoder.layer.11.attention.self.key.bias', 'cross_attention.layer.0.intermediate.dense.weight', 'BertEncoder.layer.2.attention.self.value.weight', 'BertEncoder.layer.8.attention.self.key.weight', 'BertEncoder.layer.5.attention.self.value.bias', 'BertEncoder.layer.5.intermediate.dense.bias', 'BertEncoder.layer.11.attention.self.value.bias', 'BertEncoder.layer.10.attention.self.value.bias', 'BertEncoder.layer.3.attention.self.query.weight', 'BertEncoder.layer.6.output.dense.weight', 'BertEncoder.layer.2.attention.self.query.bias', 'BertEncoder.layer.4.output.LayerNorm.bias', 'BertEncoder.layer.0.output.dense.bias', 'BertEncoder.layer.9.attention.output.LayerNorm.weight', 'BertEncoder.layer.4.output.dense.bias', 'BertEncoder.layer.11.output.dense.weight', 'BertEncoder.layer.8.attention.self.key.bias', 'BertEncoder.layer.11.output.dense.bias', 'BertEncoder.layer.3.attention.self.value.weight', 'BertEncoder.layer.9.attention.output.LayerNorm.bias', 'BertEncoder.layer.0.attention.self.value.bias', 'BertEncoder.layer.11.attention.self.query.weight', 'BertEncoder.layer.0.attention.output.dense.bias', 'BertEncoder.layer.9.attention.self.value.bias', 'BertEncoder.layer.9.output.dense.weight', 'BertEncoder.layer.6.attention.output.LayerNorm.weight', 'BertEncoder.layer.9.output.LayerNorm.bias', 'text_pooler1.dense.weight', 'BertEncoder.layer.6.intermediate.dense.bias', 'BertEncoder.layer.7.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.attention.output.dense.bias', 'linear.weight', 'BertEncoder.layer.5.attention.self.value.weight', 'cross_attention.layer.0.output.dense.weight', 'cross_attention.layer.0.attention.output.dense.bias', 'BertEncoder.layer.5.output.dense.bias', 'BertEncoder.layer.3.attention.output.dense.bias', 'BertEncoder.layer.6.attention.output.LayerNorm.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.output.LayerNorm.weight', 'BertEncoder.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.5.intermediate.dense.weight', 'BertEncoder.layer.3.attention.self.key.bias', 'BertEncoder.layer.9.output.dense.bias', 'BertEncoder.layer.7.intermediate.dense.bias', 'BertEncoder.layer.1.attention.self.query.weight', 'BertEncoder.layer.0.intermediate.dense.weight', 'BertEncoder.layer.0.attention.self.value.weight', 'BertEncoder.layer.4.attention.self.key.bias', 'BertEncoder.layer.3.attention.self.key.weight', 'BertEncoder.layer.7.output.dense.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.output.dense.bias', 'BertEncoder.layer.6.attention.self.query.weight', 'BertEncoder.layer.6.attention.self.query.bias', 'BertEncoder.layer.3.intermediate.dense.weight', 'BertEncoder.layer.10.attention.self.query.bias', 'BertEncoder.layer.7.intermediate.dense.weight', 'BertEncoder.layer.8.attention.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.value.bias', 'cross_attention.layer.0.attention.output.LayerNorm.bias', 'text_pooler1.dense.bias', 'BertEncoder.layer.3.output.dense.bias', 'BertEncoder.layer.3.attention.output.dense.weight', 'BertEncoder.layer.5.attention.output.dense.bias', 'cross_attention.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.output.dense.bias', 'BertEncoder.layer.8.output.dense.weight', 'BertEncoder.layer.6.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.output.dense.weight', 'BertEncoder.layer.8.output.LayerNorm.bias', 'BertEncoder.layer.6.attention.self.value.weight', 'BertEncoder.layer.11.attention.output.dense.bias', 'BertEncoder.layer.1.attention.self.key.weight', 'BertEncoder.layer.9.attention.self.query.bias', 'BertEncoder.layer.3.attention.self.query.bias', 'linear.bias', 'BertEncoder.layer.8.attention.self.query.weight', 'BertEncoder.layer.7.output.dense.weight', 'BertEncoder.layer.10.attention.output.dense.bias', 'BertEncoder.layer.4.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.intermediate.dense.weight', 'BertEncoder.layer.8.attention.self.query.bias', 'BertEncoder.layer.1.attention.output.LayerNorm.weight', 'BertEncoder.layer.3.attention.output.LayerNorm.bias', 'BertEncoder.layer.9.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.output.dense.weight', 'BertEncoder.layer.1.intermediate.dense.bias', 'BertEncoder.layer.9.intermediate.dense.bias', 'BertEncoder.layer.7.attention.self.query.weight', 'BertEncoder.layer.11.attention.output.dense.weight', 'BertEncoder.layer.7.attention.self.query.bias', 'BertEncoder.layer.9.attention.self.value.weight', 'BertEncoder.layer.4.attention.self.value.weight', 'BertEncoder.layer.8.output.dense.bias', 'BertEncoder.layer.10.attention.self.key.bias', 'BertEncoder.layer.10.intermediate.dense.bias', 'BertEncoder.layer.5.attention.self.query.weight', 'BertEncoder.layer.7.attention.self.key.bias', 'text_pooler.dense.weight', 'BertEncoder.layer.8.attention.self.value.bias', 'BertEncoder.layer.10.attention.self.key.weight', 'BertEncoder.layer.6.output.dense.bias', 'BertEncoder.layer.4.attention.output.dense.bias', 'BertEncoder.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.self.query.weight', 'img_pooler.dense.bias', 'BertEncoder.layer.2.attention.self.value.bias', 'BertEncoder.layer.3.attention.self.value.bias', 'BertEncoder.layer.9.attention.self.key.weight', 'BertEncoder.layer.9.attention.self.key.bias', 'BertEncoder.layer.5.attention.self.key.bias', 'BertEncoder.layer.2.intermediate.dense.weight', 'BertEncoder.layer.1.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.output.dense.weight', 'BertEncoder.layer.3.output.LayerNorm.bias', 'BertEncoder.layer.0.attention.self.query.bias', 'BertEncoder.layer.0.attention.self.query.weight', 'BertEncoder.layer.11.attention.self.query.bias', 'BertEncoder.layer.11.attention.self.key.weight', 'cross_attention.layer.0.attention.self.key.weight', 'BertEncoder.layer.1.output.LayerNorm.weight', 'BertEncoder.layer.2.attention.self.key.weight', 'BertEncoder.layer.2.output.dense.weight', 'BertEncoder.layer.2.attention.self.key.bias', 'BertEncoder.layer.8.intermediate.dense.weight', 'BertEncoder.layer.4.output.dense.weight', 'BertEncoder.layer.11.output.LayerNorm.weight', 'BertEncoder.layer.8.attention.self.value.weight', 'BertEncoder.layer.9.attention.output.dense.bias', 'BertEncoder.layer.0.intermediate.dense.bias', 'cross_attention.layer.0.attention.output.dense.weight', 'BertEncoder.layer.4.attention.self.query.bias', 'BertEncoder.layer.8.attention.output.dense.bias', 'BertEncoder.layer.11.output.LayerNorm.bias', 'BertEncoder.layer.6.attention.self.value.bias', 'cross_attention.layer.0.attention.self.query.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.weight', 'text_pooler.dense.bias', 'BertEncoder.layer.9.intermediate.dense.weight', 'BertEncoder.layer.1.attention.self.query.bias', 'BertEncoder.layer.5.output.LayerNorm.weight', 'BertEncoder.layer.5.attention.self.key.weight', 'BertEncoder.layer.1.attention.output.LayerNorm.bias', 'BertEncoder.layer.9.attention.output.dense.weight', 'BertEncoder.layer.4.attention.self.value.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.value.weight', 'BertEncoder.layer.2.output.LayerNorm.bias', 'cross_attention.layer.0.attention.self.key.bias', 'BertEncoder.layer.11.attention.self.value.weight', 'BertEncoder.layer.0.attention.self.key.weight', 'classifier.weight', 'BertEncoder.layer.2.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.self.value.weight', 'BertEncoder.layer.6.attention.self.key.bias', 'BertEncoder.layer.1.output.dense.weight', 'BertEncoder.layer.7.attention.self.value.bias', 'BertEncoder.layer.0.attention.output.dense.weight', 'BertEncoder.layer.3.output.LayerNorm.weight', 'BertEncoder.layer.10.intermediate.dense.weight', 'BertEncoder.layer.2.output.dense.bias', 'BertEncoder.layer.3.intermediate.dense.bias', 'BertEncoder.layer.2.attention.self.query.weight', 'BertEncoder.layer.0.attention.self.key.bias', 'BertEncoder.layer.1.attention.output.dense.bias', 'cross_attention.layer.0.attention.self.value.weight', 'BertEncoder.layer.1.intermediate.dense.weight', 'cross_attention.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.10.output.LayerNorm.bias', 'BertEncoder.layer.7.output.LayerNorm.weight', 'cross_attention.layer.0.intermediate.dense.bias', 'img_pooler.dense.weight', 'BertEncoder.layer.6.output.LayerNorm.weight', 'BertEncoder.layer.4.intermediate.dense.bias', 'BertEncoder.layer.5.attention.output.dense.weight', 'BertEncoder.layer.6.intermediate.dense.weight', 'BertEncoder.layer.1.attention.self.key.bias', 'BertEncoder.layer.7.attention.output.dense.weight', 'BertEncoder.layer.1.output.dense.bias', 'classifier.bias', 'BertEncoder.layer.7.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.self.query.weight', 'BertEncoder.layer.4.attention.output.LayerNorm.weight', 'BertEncoder.layer.0.attention.output.LayerNorm.weight', 'cross_attention.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.8.intermediate.dense.bias', 'BertEncoder.layer.9.attention.self.query.weight', 'cross_attention.layer.0.attention.self.query.weight', 'BertEncoder.layer.3.attention.output.LayerNorm.weight', 'BertEncoder.layer.1.attention.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","3699\n","07/09/2022 09:50:35 - INFO - processors.util -   Start Training\n","epoch 0 traning loss 0.9013210957249006: 100% 78/78 [00:23<00:00,  3.30it/s]\n","07/09/2022 09:50:58 - INFO - processors.util -   Start Evaluation\n","epoch 0 dev loss 0.7678567155411369: 100% 19/19 [00:01<00:00, 14.06it/s]\n","eval_accuracy: 0.6511627906976745 f_score: 0.5959908807216029\n","epoch 1 traning loss 0.7300865168754871: 100% 78/78 [00:25<00:00,  3.10it/s]\n","07/09/2022 09:51:29 - INFO - processors.util -   Start Evaluation\n","epoch 1 dev loss 0.7298573459449568: 100% 19/19 [00:01<00:00, 13.93it/s]\n","eval_accuracy: 0.6943521594684385 f_score: 0.6609565393431767\n","epoch 2 traning loss 0.45128726999824625: 100% 78/78 [00:23<00:00,  3.27it/s]\n","07/09/2022 09:51:59 - INFO - processors.util -   Start Evaluation\n","epoch 2 dev loss 0.8084831598557924: 100% 19/19 [00:01<00:00, 14.71it/s]\n","eval_accuracy: 0.7043189368770764 f_score: 0.679011538396308\n","epoch 3 traning loss 0.21696669541490385: 100% 78/78 [00:24<00:00,  3.22it/s]\n","07/09/2022 09:52:28 - INFO - processors.util -   Start Evaluation\n","epoch 3 dev loss 1.0614917670425617: 100% 19/19 [00:01<00:00, 12.83it/s]\n","eval_accuracy: 0.6843853820598007 f_score: 0.6771540991827427\n","epoch 4 traning loss 0.1058114192281396: 100% 78/78 [00:24<00:00,  3.17it/s]\n","07/09/2022 09:52:55 - INFO - processors.util -   Start Evaluation\n","epoch 4 dev loss 1.189566144817754: 100% 19/19 [00:01<00:00, 14.45it/s]\n","eval_accuracy: 0.6877076411960132 f_score: 0.674267592872244\n","epoch 5 traning loss 0.06703392158931074: 100% 78/78 [00:23<00:00,  3.28it/s]\n","07/09/2022 09:53:20 - INFO - processors.util -   Start Evaluation\n","epoch 5 dev loss 1.3267693080400165: 100% 19/19 [00:01<00:00, 14.59it/s]\n","eval_accuracy: 0.6710963455149501 f_score: 0.6680361278248576\n","epoch 6 traning loss 0.05303069769601839: 100% 78/78 [00:23<00:00,  3.26it/s]\n","07/09/2022 09:53:45 - INFO - processors.util -   Start Evaluation\n","epoch 6 dev loss 1.3410223785199618: 100% 19/19 [00:01<00:00, 14.33it/s]\n","eval_accuracy: 0.6810631229235881 f_score: 0.6735608670736506\n","epoch 7 traning loss 0.03817767138258578: 100% 78/78 [00:24<00:00,  3.22it/s]\n","07/09/2022 09:54:11 - INFO - processors.util -   Start Evaluation\n","epoch 7 dev loss 1.4002579701574225: 100% 19/19 [00:01<00:00, 14.37it/s]\n","eval_accuracy: 0.6943521594684385 f_score: 0.6904050072106238\n","epoch 8 traning loss 0.03443479480054707: 100% 78/78 [00:23<00:00,  3.26it/s]\n","07/09/2022 09:54:36 - INFO - processors.util -   Start Evaluation\n","epoch 8 dev loss 1.4534267971390171: 100% 19/19 [00:01<00:00, 14.48it/s]\n","eval_accuracy: 0.6943521594684385 f_score: 0.6848182888776398\n","epoch 9 traning loss 0.03057709309714249: 100% 78/78 [00:24<00:00,  3.24it/s]\n","07/09/2022 09:55:01 - INFO - processors.util -   Start Evaluation\n","epoch 9 dev loss 1.4675603477578414: 100% 19/19 [00:01<00:00, 14.35it/s]\n","eval_accuracy: 0.6943521594684385 f_score: 0.685174094245329\n"]}]},{"cell_type":"markdown","source":["输入文字+图像"],"metadata":{"id":"ui_itATxfrEg"}},{"cell_type":"code","source":["!sh run.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVM_s2L-X5BQ","executionInfo":{"status":"ok","timestamp":1657362048579,"user_tz":-480,"elapsed":887633,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}},"outputId":"ff8a1987-290f-4bd9-abc1-82799dc418e1"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing mymodel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing mymodel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing mymodel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of mymodel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['BertEncoder.layer.1.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.weight', 'BertEncoder.layer.11.output.dense.weight', 'BertEncoder.layer.4.attention.output.LayerNorm.bias', 'BertEncoder.layer.9.intermediate.dense.weight', 'BertEncoder.layer.1.attention.self.value.bias', 'BertEncoder.layer.4.output.dense.weight', 'BertEncoder.layer.9.attention.self.value.weight', 'BertEncoder.layer.11.attention.self.key.weight', 'BertEncoder.layer.3.output.dense.weight', 'BertEncoder.layer.4.attention.self.key.bias', 'BertEncoder.layer.10.attention.self.value.bias', 'BertEncoder.layer.3.attention.output.dense.weight', 'BertEncoder.layer.5.intermediate.dense.bias', 'BertEncoder.layer.7.attention.output.dense.weight', 'BertEncoder.layer.6.attention.output.LayerNorm.weight', 'BertEncoder.layer.2.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.self.key.weight', 'BertEncoder.layer.5.output.LayerNorm.weight', 'BertEncoder.layer.0.intermediate.dense.bias', 'BertEncoder.layer.6.output.dense.weight', 'BertEncoder.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.self.query.weight', 'BertEncoder.layer.6.output.LayerNorm.weight', 'BertEncoder.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.query.weight', 'BertEncoder.layer.5.intermediate.dense.weight', 'BertEncoder.layer.1.output.dense.weight', 'text_pooler1.dense.bias', 'BertEncoder.layer.2.attention.self.query.bias', 'BertEncoder.layer.9.attention.self.query.bias', 'text_pooler.dense.weight', 'BertEncoder.layer.1.attention.output.LayerNorm.weight', 'BertEncoder.layer.0.output.dense.bias', 'BertEncoder.layer.9.output.dense.bias', 'cross_attention.layer.0.attention.self.key.bias', 'BertEncoder.layer.1.attention.self.value.weight', 'cross_attention.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.intermediate.dense.weight', 'BertEncoder.layer.3.attention.self.value.weight', 'BertEncoder.layer.3.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.output.dense.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.bias', 'BertEncoder.layer.7.output.LayerNorm.bias', 'BertEncoder.layer.6.attention.self.query.weight', 'BertEncoder.layer.6.attention.self.value.weight', 'BertEncoder.layer.3.attention.output.LayerNorm.weight', 'BertEncoder.layer.0.attention.self.query.bias', 'BertEncoder.layer.10.attention.self.key.weight', 'BertEncoder.layer.11.attention.self.value.bias', 'BertEncoder.layer.10.attention.output.dense.weight', 'BertEncoder.layer.4.output.LayerNorm.bias', 'BertEncoder.layer.5.output.dense.bias', 'BertEncoder.layer.7.attention.self.key.bias', 'BertEncoder.layer.0.attention.self.value.weight', 'BertEncoder.layer.10.output.dense.weight', 'BertEncoder.layer.10.intermediate.dense.weight', 'BertEncoder.layer.3.attention.self.query.bias', 'BertEncoder.layer.11.attention.output.dense.bias', 'BertEncoder.layer.6.attention.self.key.bias', 'BertEncoder.layer.5.output.dense.weight', 'BertEncoder.layer.6.attention.self.query.bias', 'BertEncoder.layer.5.attention.self.key.bias', 'BertEncoder.layer.1.intermediate.dense.weight', 'BertEncoder.layer.4.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.self.value.bias', 'BertEncoder.layer.7.intermediate.dense.bias', 'BertEncoder.layer.9.attention.output.dense.weight', 'BertEncoder.layer.5.attention.self.query.bias', 'BertEncoder.layer.8.intermediate.dense.bias', 'BertEncoder.layer.9.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.intermediate.dense.bias', 'cross_attention.layer.0.attention.self.query.weight', 'BertEncoder.layer.4.attention.output.dense.weight', 'BertEncoder.layer.1.output.dense.bias', 'BertEncoder.layer.8.output.LayerNorm.weight', 'BertEncoder.layer.4.attention.self.value.weight', 'img_pooler.dense.bias', 'BertEncoder.layer.3.attention.self.key.weight', 'BertEncoder.layer.11.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.output.dense.bias', 'BertEncoder.layer.1.attention.output.LayerNorm.bias', 'BertEncoder.layer.0.attention.self.query.weight', 'BertEncoder.layer.7.attention.self.value.weight', 'BertEncoder.layer.10.output.LayerNorm.weight', 'BertEncoder.layer.8.attention.self.value.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.self.query.bias', 'BertEncoder.layer.8.attention.output.dense.weight', 'BertEncoder.layer.4.attention.self.query.weight', 'BertEncoder.layer.2.intermediate.dense.weight', 'BertEncoder.layer.1.attention.output.dense.weight', 'cross_attention.layer.0.attention.self.value.bias', 'BertEncoder.layer.6.attention.output.LayerNorm.bias', 'BertEncoder.layer.4.attention.output.LayerNorm.weight', 'cross_attention.layer.0.attention.output.dense.bias', 'BertEncoder.layer.9.intermediate.dense.bias', 'cross_attention.layer.0.output.dense.bias', 'BertEncoder.layer.9.output.LayerNorm.weight', 'BertEncoder.layer.10.attention.self.key.bias', 'BertEncoder.layer.6.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.self.key.bias', 'BertEncoder.layer.4.output.dense.bias', 'classifier.weight', 'BertEncoder.layer.4.intermediate.dense.bias', 'BertEncoder.layer.7.output.dense.weight', 'BertEncoder.layer.8.output.dense.weight', 'BertEncoder.layer.8.intermediate.dense.weight', 'BertEncoder.layer.0.intermediate.dense.weight', 'BertEncoder.layer.10.output.dense.bias', 'BertEncoder.layer.6.output.dense.bias', 'BertEncoder.layer.5.attention.self.value.bias', 'BertEncoder.layer.2.intermediate.dense.bias', 'text_pooler.dense.bias', 'BertEncoder.layer.10.attention.self.value.weight', 'BertEncoder.layer.7.attention.self.key.weight', 'classifier.bias', 'BertEncoder.layer.5.attention.self.key.weight', 'cross_attention.layer.0.attention.output.dense.weight', 'BertEncoder.layer.3.attention.self.value.bias', 'BertEncoder.layer.0.output.dense.weight', 'BertEncoder.layer.0.attention.output.dense.bias', 'BertEncoder.layer.3.intermediate.dense.weight', 'BertEncoder.layer.2.attention.self.query.weight', 'cross_attention.layer.0.attention.self.value.weight', 'BertEncoder.layer.11.attention.self.query.bias', 'BertEncoder.layer.3.attention.self.key.bias', 'BertEncoder.layer.4.intermediate.dense.weight', 'img_pooler.dense.weight', 'BertEncoder.layer.9.attention.output.dense.bias', 'BertEncoder.layer.4.attention.self.value.bias', 'BertEncoder.layer.1.attention.self.query.bias', 'BertEncoder.layer.6.intermediate.dense.weight', 'BertEncoder.layer.11.attention.self.query.weight', 'BertEncoder.layer.11.attention.self.value.weight', 'BertEncoder.layer.3.attention.self.query.weight', 'BertEncoder.layer.5.attention.output.LayerNorm.weight', 'BertEncoder.layer.9.attention.self.value.bias', 'BertEncoder.layer.0.attention.self.value.bias', 'text_pooler1.dense.weight', 'BertEncoder.layer.11.attention.output.dense.weight', 'cross_attention.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.10.output.LayerNorm.bias', 'BertEncoder.layer.0.attention.self.key.weight', 'BertEncoder.layer.11.intermediate.dense.weight', 'BertEncoder.layer.7.attention.self.query.bias', 'BertEncoder.layer.5.attention.output.dense.bias', 'BertEncoder.layer.2.output.dense.bias', 'BertEncoder.layer.8.output.dense.bias', 'BertEncoder.layer.6.attention.output.dense.weight', 'BertEncoder.layer.11.output.LayerNorm.bias', 'BertEncoder.layer.2.attention.self.value.bias', 'BertEncoder.layer.3.output.LayerNorm.weight', 'cross_attention.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.2.attention.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.output.LayerNorm.bias', 'BertEncoder.layer.9.output.LayerNorm.bias', 'cross_attention.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.3.output.LayerNorm.bias', 'BertEncoder.layer.2.attention.output.dense.weight', 'BertEncoder.layer.2.attention.self.key.weight', 'BertEncoder.layer.10.attention.output.LayerNorm.bias', 'BertEncoder.layer.5.output.LayerNorm.bias', 'linear.bias', 'cross_attention.layer.0.attention.self.query.bias', 'BertEncoder.layer.3.output.dense.bias', 'BertEncoder.layer.1.attention.output.dense.bias', 'BertEncoder.layer.8.attention.self.value.weight', 'BertEncoder.layer.6.attention.self.value.bias', 'BertEncoder.layer.2.attention.output.dense.bias', 'BertEncoder.layer.9.output.dense.weight', 'BertEncoder.layer.10.attention.output.dense.bias', 'BertEncoder.layer.7.attention.output.dense.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.bias', 'cross_attention.layer.0.intermediate.dense.weight', 'BertEncoder.layer.11.output.LayerNorm.weight', 'BertEncoder.layer.7.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.self.key.weight', 'BertEncoder.layer.5.attention.self.value.weight', 'BertEncoder.layer.8.attention.output.dense.bias', 'BertEncoder.layer.9.attention.output.LayerNorm.bias', 'BertEncoder.layer.10.attention.self.query.bias', 'BertEncoder.layer.0.attention.self.key.bias', 'BertEncoder.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.3.attention.output.dense.bias', 'BertEncoder.layer.5.attention.output.dense.weight', 'BertEncoder.layer.8.attention.self.query.weight', 'BertEncoder.layer.8.attention.self.query.bias', 'BertEncoder.layer.7.attention.output.LayerNorm.weight', 'BertEncoder.layer.0.attention.output.dense.weight', 'cross_attention.layer.0.intermediate.dense.bias', 'BertEncoder.layer.1.attention.self.key.weight', 'BertEncoder.layer.10.intermediate.dense.bias', 'BertEncoder.layer.8.attention.self.key.bias', 'BertEncoder.layer.4.attention.output.dense.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.weight', 'BertEncoder.layer.3.intermediate.dense.bias', 'BertEncoder.layer.2.attention.self.key.bias', 'BertEncoder.layer.11.intermediate.dense.bias', 'linear.weight', 'BertEncoder.layer.2.attention.self.value.weight', 'cross_attention.layer.0.output.dense.weight', 'BertEncoder.layer.1.intermediate.dense.bias', 'BertEncoder.layer.1.attention.self.key.bias', 'BertEncoder.layer.5.attention.self.query.weight', 'BertEncoder.layer.8.output.LayerNorm.bias', 'BertEncoder.layer.9.attention.self.query.weight', 'BertEncoder.layer.2.output.dense.weight', 'BertEncoder.layer.9.attention.self.key.weight', 'BertEncoder.layer.2.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.self.query.weight', 'BertEncoder.layer.1.output.LayerNorm.weight', 'cross_attention.layer.0.attention.self.key.weight', 'BertEncoder.layer.2.attention.output.LayerNorm.bias', 'BertEncoder.layer.11.output.dense.bias', 'BertEncoder.layer.9.attention.self.key.bias', 'BertEncoder.layer.4.attention.self.key.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","3699\n","tcmalloc: large alloc 2227216384 bytes == 0x15dcb6000 @  0x7f2ea1d5eb6b 0x7f2ea1d7e379 0x7f2ddcc0450e 0x7f2ddcbf67c2 0x7f2e16fb12d8 0x7f2e16fb1de7 0x7f2e176c2928 0x7f2e17055b07 0x7f2e17056415 0x7f2e1772be82 0x7f2e175fea2d 0x7f2e170612e1 0x7f2e17829622 0x7f2e1733a79a 0x7f2e1705d1da 0x7f2e1782a5b2 0x7f2e173fe7c2 0x7f2e1842377a 0x7f2e18423d65 0x7f2e1744a35d 0x7f2e920ac2e0 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x604173\n","07/09/2022 09:55:53 - INFO - processors.util -   Start Training\n","epoch 0 traning loss 0.9311939844718347: 100% 78/78 [02:18<00:00,  1.78s/it]\n","07/09/2022 09:58:12 - INFO - processors.util -   Start Evaluation\n","epoch 0 dev loss 0.9128630882815311: 100% 19/19 [00:09<00:00,  2.11it/s]\n","eval_accuracy: 0.5880398671096345 f_score: 0.43549396016069164\n","epoch 1 traning loss 0.8354950203345373: 100% 78/78 [02:18<00:00,  1.78s/it]\n","07/09/2022 10:00:45 - INFO - processors.util -   Start Evaluation\n","epoch 1 dev loss 0.688565665169766: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7441860465116279 f_score: 0.7286238335791637\n","epoch 2 traning loss 0.6197523291294391: 100% 78/78 [02:19<00:00,  1.78s/it]\n","07/09/2022 10:03:18 - INFO - processors.util -   Start Evaluation\n","epoch 2 dev loss 0.6578938678691262: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7142857142857143 f_score: 0.6749911788350089\n","epoch 3 traning loss 0.4635752219802294: 100% 78/78 [02:18<00:00,  1.77s/it]\n","07/09/2022 10:05:45 - INFO - processors.util -   Start Evaluation\n","epoch 3 dev loss 0.6678428645980986: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.760797342192691 f_score: 0.7527018129876756\n","epoch 4 traning loss 0.2921459656686355: 100% 78/78 [02:19<00:00,  1.78s/it]\n","07/09/2022 10:08:17 - INFO - processors.util -   Start Evaluation\n","epoch 4 dev loss 0.8253230323132715: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7242524916943521 f_score: 0.7253403280481305\n","epoch 5 traning loss 0.195027973359594: 100% 78/78 [02:17<00:00,  1.77s/it]\n","07/09/2022 10:10:44 - INFO - processors.util -   Start Evaluation\n","epoch 5 dev loss 0.8938808546058441: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7375415282392026 f_score: 0.7258236993640957\n","epoch 6 traning loss 0.12805461908618992: 100% 78/78 [02:18<00:00,  1.77s/it]\n","07/09/2022 10:13:11 - INFO - processors.util -   Start Evaluation\n","epoch 6 dev loss 0.86671461429643: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7441860465116279 f_score: 0.7380708992004673\n","epoch 7 traning loss 0.11180544221917024: 100% 78/78 [02:17<00:00,  1.77s/it]\n","07/09/2022 10:15:38 - INFO - processors.util -   Start Evaluation\n","epoch 7 dev loss 0.8792122542662056: 100% 19/19 [00:08<00:00,  2.11it/s]\n","eval_accuracy: 0.7541528239202658 f_score: 0.7479310518250581\n","epoch 8 traning loss 0.08079925119781341: 100% 78/78 [02:17<00:00,  1.77s/it]\n","07/09/2022 10:18:05 - INFO - processors.util -   Start Evaluation\n","epoch 8 dev loss 0.9669614443555474: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7375415282392026 f_score: 0.7311612089528357\n","epoch 9 traning loss 0.06200483379264673: 100% 78/78 [02:17<00:00,  1.77s/it]\n","07/09/2022 10:20:32 - INFO - processors.util -   Start Evaluation\n","epoch 9 dev loss 0.9560777992500287: 100% 19/19 [00:08<00:00,  2.12it/s]\n","eval_accuracy: 0.7275747508305648 f_score: 0.7220445387393891\n"]}]},{"cell_type":"markdown","source":["预测"],"metadata":{"id":"fCTcCwLxthZz"}},{"cell_type":"code","source":["!sh run_test.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3eFC5O2SI8M","executionInfo":{"status":"ok","timestamp":1657362106193,"user_tz":-480,"elapsed":57624,"user":{"displayName":"y fengyu","userId":"14118958655840234398"}},"outputId":"c1042c53-6d68-482e-f385-6b259a378326"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["run_test.sh: 2: run_test.sh: \r: not found\n","/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing mymodel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing mymodel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing mymodel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of mymodel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['BertEncoder.layer.2.attention.self.query.bias', 'BertEncoder.layer.1.attention.self.key.weight', 'BertEncoder.layer.10.attention.self.key.bias', 'BertEncoder.layer.6.attention.output.LayerNorm.weight', 'BertEncoder.layer.0.intermediate.dense.bias', 'BertEncoder.layer.6.attention.output.dense.weight', 'BertEncoder.layer.5.attention.output.LayerNorm.bias', 'BertEncoder.layer.3.attention.self.query.weight', 'BertEncoder.layer.10.attention.self.key.weight', 'cross_attention.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.self.value.weight', 'cross_attention.layer.0.attention.output.dense.weight', 'BertEncoder.layer.3.attention.self.value.weight', 'classifier.weight', 'linear.weight', 'BertEncoder.layer.4.output.dense.bias', 'cross_attention.layer.0.attention.self.value.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.bias', 'cross_attention.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.self.key.weight', 'BertEncoder.layer.0.attention.self.query.bias', 'BertEncoder.layer.7.attention.self.value.weight', 'BertEncoder.layer.2.attention.self.query.weight', 'BertEncoder.layer.5.intermediate.dense.weight', 'BertEncoder.layer.8.output.dense.bias', 'cross_attention.layer.0.output.dense.weight', 'BertEncoder.layer.8.output.dense.weight', 'BertEncoder.layer.10.attention.output.dense.bias', 'BertEncoder.layer.10.attention.output.dense.weight', 'BertEncoder.layer.9.attention.output.LayerNorm.weight', 'BertEncoder.layer.3.intermediate.dense.bias', 'BertEncoder.layer.11.output.LayerNorm.weight', 'BertEncoder.layer.8.intermediate.dense.bias', 'BertEncoder.layer.0.attention.self.key.weight', 'BertEncoder.layer.2.attention.output.LayerNorm.weight', 'cross_attention.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.6.attention.output.dense.bias', 'BertEncoder.layer.1.output.dense.bias', 'BertEncoder.layer.11.attention.output.dense.bias', 'BertEncoder.layer.7.output.dense.bias', 'BertEncoder.layer.7.attention.self.key.weight', 'BertEncoder.layer.5.attention.self.key.weight', 'BertEncoder.layer.1.attention.self.query.bias', 'BertEncoder.layer.8.output.LayerNorm.bias', 'BertEncoder.layer.0.attention.output.LayerNorm.weight', 'BertEncoder.layer.7.output.LayerNorm.bias', 'BertEncoder.layer.3.attention.self.query.bias', 'img_pooler.dense.weight', 'BertEncoder.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.5.attention.self.query.weight', 'BertEncoder.layer.2.output.dense.weight', 'BertEncoder.layer.5.output.dense.bias', 'BertEncoder.layer.5.attention.self.key.bias', 'BertEncoder.layer.9.attention.self.key.bias', 'BertEncoder.layer.3.attention.output.dense.weight', 'BertEncoder.layer.3.attention.output.dense.bias', 'BertEncoder.layer.8.attention.output.LayerNorm.bias', 'classifier.bias', 'BertEncoder.layer.6.attention.self.value.bias', 'BertEncoder.layer.3.attention.output.LayerNorm.weight', 'BertEncoder.layer.11.intermediate.dense.bias', 'BertEncoder.layer.10.attention.self.value.bias', 'cross_attention.layer.0.attention.output.dense.bias', 'BertEncoder.layer.2.attention.output.LayerNorm.bias', 'BertEncoder.layer.5.output.dense.weight', 'BertEncoder.layer.6.attention.self.key.bias', 'BertEncoder.layer.4.intermediate.dense.weight', 'BertEncoder.layer.6.attention.self.query.weight', 'BertEncoder.layer.8.attention.output.dense.bias', 'BertEncoder.layer.1.attention.self.query.weight', 'BertEncoder.layer.4.attention.self.value.bias', 'BertEncoder.layer.10.output.dense.bias', 'BertEncoder.layer.7.attention.self.key.bias', 'BertEncoder.layer.3.attention.self.key.weight', 'BertEncoder.layer.3.attention.self.key.bias', 'BertEncoder.layer.4.output.dense.weight', 'BertEncoder.layer.6.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.self.query.weight', 'BertEncoder.layer.2.attention.self.value.bias', 'BertEncoder.layer.6.attention.self.key.weight', 'BertEncoder.layer.11.attention.output.LayerNorm.bias', 'cross_attention.layer.0.attention.self.query.bias', 'cross_attention.layer.0.attention.self.key.weight', 'BertEncoder.layer.9.intermediate.dense.weight', 'BertEncoder.layer.7.intermediate.dense.weight', 'BertEncoder.layer.4.intermediate.dense.bias', 'BertEncoder.layer.2.output.dense.bias', 'BertEncoder.layer.1.output.LayerNorm.weight', 'BertEncoder.layer.1.intermediate.dense.bias', 'BertEncoder.layer.10.intermediate.dense.bias', 'BertEncoder.layer.11.attention.output.LayerNorm.weight', 'BertEncoder.layer.8.attention.self.query.weight', 'BertEncoder.layer.1.attention.self.value.bias', 'BertEncoder.layer.9.output.dense.weight', 'BertEncoder.layer.4.attention.self.key.weight', 'BertEncoder.layer.11.output.dense.bias', 'BertEncoder.layer.8.attention.self.value.weight', 'BertEncoder.layer.9.output.LayerNorm.weight', 'text_pooler1.dense.bias', 'BertEncoder.layer.5.output.LayerNorm.weight', 'BertEncoder.layer.9.attention.output.dense.bias', 'BertEncoder.layer.1.output.LayerNorm.bias', 'BertEncoder.layer.6.output.LayerNorm.bias', 'BertEncoder.layer.9.attention.self.key.weight', 'linear.bias', 'BertEncoder.layer.11.output.dense.weight', 'BertEncoder.layer.9.attention.self.query.weight', 'BertEncoder.layer.7.intermediate.dense.bias', 'BertEncoder.layer.4.attention.output.dense.weight', 'BertEncoder.layer.7.attention.self.value.bias', 'BertEncoder.layer.6.intermediate.dense.weight', 'BertEncoder.layer.1.output.dense.weight', 'BertEncoder.layer.0.attention.self.key.bias', 'BertEncoder.layer.0.attention.self.value.weight', 'BertEncoder.layer.10.attention.self.value.weight', 'BertEncoder.layer.4.output.LayerNorm.weight', 'BertEncoder.layer.5.attention.output.dense.weight', 'text_pooler.dense.bias', 'text_pooler.dense.weight', 'BertEncoder.layer.4.attention.output.LayerNorm.bias', 'BertEncoder.layer.8.output.LayerNorm.weight', 'BertEncoder.layer.11.attention.self.value.bias', 'text_pooler1.dense.weight', 'BertEncoder.layer.8.attention.self.key.weight', 'BertEncoder.layer.2.attention.self.value.weight', 'BertEncoder.layer.0.attention.self.query.weight', 'BertEncoder.layer.0.attention.self.value.bias', 'BertEncoder.layer.0.attention.output.LayerNorm.bias', 'BertEncoder.layer.3.intermediate.dense.weight', 'BertEncoder.layer.10.output.LayerNorm.weight', 'BertEncoder.layer.11.attention.self.key.bias', 'BertEncoder.layer.10.attention.output.LayerNorm.weight', 'BertEncoder.layer.2.output.LayerNorm.weight', 'BertEncoder.layer.4.output.LayerNorm.bias', 'img_pooler.dense.bias', 'BertEncoder.layer.1.attention.self.key.bias', 'BertEncoder.layer.10.intermediate.dense.weight', 'BertEncoder.layer.9.output.dense.bias', 'BertEncoder.layer.5.intermediate.dense.bias', 'BertEncoder.layer.0.intermediate.dense.weight', 'BertEncoder.layer.11.output.LayerNorm.bias', 'BertEncoder.layer.5.attention.self.value.bias', 'BertEncoder.layer.0.output.dense.weight', 'BertEncoder.layer.6.output.dense.weight', 'cross_attention.layer.0.intermediate.dense.bias', 'BertEncoder.layer.5.attention.self.query.bias', 'BertEncoder.layer.9.attention.output.LayerNorm.bias', 'BertEncoder.layer.6.attention.output.LayerNorm.bias', 'cross_attention.layer.0.intermediate.dense.weight', 'BertEncoder.layer.9.attention.output.dense.weight', 'BertEncoder.layer.7.output.dense.weight', 'BertEncoder.layer.10.attention.self.query.bias', 'BertEncoder.layer.1.attention.output.LayerNorm.bias', 'BertEncoder.layer.5.attention.self.value.weight', 'BertEncoder.layer.0.attention.output.dense.bias', 'BertEncoder.layer.2.output.LayerNorm.bias', 'BertEncoder.layer.7.attention.output.dense.bias', 'BertEncoder.layer.4.attention.self.query.bias', 'BertEncoder.layer.2.attention.output.dense.bias', 'BertEncoder.layer.3.output.dense.weight', 'BertEncoder.layer.8.attention.output.LayerNorm.weight', 'BertEncoder.layer.7.attention.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.self.value.bias', 'BertEncoder.layer.9.attention.self.value.weight', 'BertEncoder.layer.8.attention.self.query.bias', 'BertEncoder.layer.0.output.LayerNorm.weight', 'BertEncoder.layer.11.attention.self.query.bias', 'cross_attention.layer.0.output.LayerNorm.bias', 'BertEncoder.layer.1.attention.self.value.weight', 'cross_attention.layer.0.attention.self.query.weight', 'BertEncoder.layer.7.attention.self.query.bias', 'BertEncoder.layer.1.attention.output.LayerNorm.weight', 'BertEncoder.layer.4.attention.self.query.weight', 'BertEncoder.layer.0.attention.output.dense.weight', 'BertEncoder.layer.4.attention.output.LayerNorm.weight', 'BertEncoder.layer.1.attention.output.dense.bias', 'BertEncoder.layer.3.output.LayerNorm.weight', 'BertEncoder.layer.9.attention.self.value.bias', 'BertEncoder.layer.8.attention.self.key.bias', 'BertEncoder.layer.9.intermediate.dense.bias', 'BertEncoder.layer.6.intermediate.dense.bias', 'BertEncoder.layer.3.attention.output.LayerNorm.bias', 'BertEncoder.layer.5.attention.output.LayerNorm.weight', 'BertEncoder.layer.4.attention.output.dense.bias', 'BertEncoder.layer.2.attention.output.dense.weight', 'BertEncoder.layer.10.output.LayerNorm.bias', 'BertEncoder.layer.9.attention.self.query.bias', 'BertEncoder.layer.7.attention.output.LayerNorm.weight', 'BertEncoder.layer.1.intermediate.dense.weight', 'BertEncoder.layer.8.intermediate.dense.weight', 'BertEncoder.layer.1.attention.output.dense.weight', 'BertEncoder.layer.9.output.LayerNorm.bias', 'BertEncoder.layer.11.attention.self.query.weight', 'BertEncoder.layer.4.attention.self.key.bias', 'BertEncoder.layer.4.attention.self.value.weight', 'BertEncoder.layer.5.output.LayerNorm.bias', 'BertEncoder.layer.8.attention.output.dense.weight', 'cross_attention.layer.0.attention.self.value.weight', 'BertEncoder.layer.11.attention.output.dense.weight', 'BertEncoder.layer.6.output.dense.bias', 'BertEncoder.layer.10.output.dense.weight', 'BertEncoder.layer.3.output.dense.bias', 'BertEncoder.layer.5.attention.output.dense.bias', 'BertEncoder.layer.7.output.LayerNorm.weight', 'BertEncoder.layer.0.output.dense.bias', 'BertEncoder.layer.11.attention.self.value.weight', 'BertEncoder.layer.2.intermediate.dense.weight', 'BertEncoder.layer.10.attention.self.query.weight', 'cross_attention.layer.0.output.dense.bias', 'cross_attention.layer.0.attention.self.key.bias', 'BertEncoder.layer.6.attention.self.query.bias', 'BertEncoder.layer.2.attention.self.key.bias', 'BertEncoder.layer.7.attention.output.dense.weight', 'BertEncoder.layer.2.intermediate.dense.bias', 'BertEncoder.layer.3.output.LayerNorm.bias', 'BertEncoder.layer.3.attention.self.value.bias', 'BertEncoder.layer.11.intermediate.dense.weight', 'BertEncoder.layer.2.attention.self.key.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","07/09/2022 10:21:34 - INFO - processors.util -   Start Prediction\n","Testing: 100% 32/32 [00:07<00:00,  4.53it/s]\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"code.ipynb","provenance":[{"file_id":"1kbcomdfsiBpl0MuY0-BlfNSY6wSw_QLj","timestamp":1652371605573}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}